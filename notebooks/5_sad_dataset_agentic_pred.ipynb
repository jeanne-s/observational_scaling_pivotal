{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch2/jsalle/ObsScaling\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import copy\n",
    "\n",
    "%cd ..\n",
    "from utils import *\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base benchmarks (MMLU, GSM8K, etc.)\n",
    "instruct_llm_benchmark_eval = load_instruct_llm_benchmark_eval()\n",
    "\n",
    "# Agent benchmarks\n",
    "eval_result_path = \"./eval_results/instruct_llm_agent_eval.csv\"\n",
    "agent_eval = pd.read_csv(eval_result_path)\n",
    "\n",
    "instruct_llm_eval_with_agent = pd.merge(instruct_llm_benchmark_eval, agent_eval, on=\"Model\")\n",
    "eval_with_agent_models = instruct_llm_eval_with_agent['Model'].unique().tolist()\n",
    "\n",
    "# SAD benchmarks\n",
    "sad_eval = pd.read_csv(\"./eval_results/sad_benchmark_results.csv\")\n",
    "sad_eval.rename(columns={'model': 'Model'}, inplace=True)\n",
    "sad_eval_models = sad_eval['Model'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sad_models = sad_eval[\"Model\"].unique().tolist()\n",
    "sad_types = sad_eval[\"type\"].unique().tolist()\n",
    "sad_variants = sad_eval[\"variant\"].unique().tolist()\n",
    "\n",
    "\n",
    "sad_intermediary_df = pd.DataFrame()\n",
    "\n",
    "for model in sad_models:\n",
    "    temp_dict = {\n",
    "        \"Model\": model,\n",
    "    }\n",
    "\n",
    "    for t in sad_types:\n",
    "        for v in sad_variants:\n",
    "            temp_dict.update(\n",
    "                {f'{t}_{v}': sad_eval[(sad_eval[\"Model\"] == model) & (sad_eval[\"type\"] == t) & (sad_eval[\"variant\"] == v)][\"score\"].values[0]}\n",
    "            )\n",
    "    temp_df = pd.DataFrame(temp_dict, index=[0])\n",
    "\n",
    "    sad_intermediary_df = pd.concat([sad_intermediary_df, temp_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>SAD_Plain_Prompt</th>\n",
       "      <th>SAD_Situating_Prompt</th>\n",
       "      <th>SAD-lite_Plain_Prompt</th>\n",
       "      <th>SAD-lite_Situating_Prompt</th>\n",
       "      <th>SAD-mini_Plain_Prompt</th>\n",
       "      <th>SAD-mini_Situating_Prompt</th>\n",
       "      <th>facts_Plain_Prompt</th>\n",
       "      <th>facts_Situating_Prompt</th>\n",
       "      <th>influence_Plain_Prompt</th>\n",
       "      <th>...</th>\n",
       "      <th>introspection_Plain_Prompt</th>\n",
       "      <th>introspection_Situating_Prompt</th>\n",
       "      <th>stages_Plain_Prompt</th>\n",
       "      <th>stages_Situating_Prompt</th>\n",
       "      <th>self-recognition_Plain_Prompt</th>\n",
       "      <th>self-recognition_Situating_Prompt</th>\n",
       "      <th>id-leverage_Plain_Prompt</th>\n",
       "      <th>id-leverage_Situating_Prompt</th>\n",
       "      <th>anti-imitation_Plain_Prompt</th>\n",
       "      <th>anti-imitation_Situating_Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama-2-7b</td>\n",
       "      <td>0.328841</td>\n",
       "      <td>0.306368</td>\n",
       "      <td>0.364873</td>\n",
       "      <td>0.340016</td>\n",
       "      <td>0.471816</td>\n",
       "      <td>0.418833</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>0.360935</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379519</td>\n",
       "      <td>0.373241</td>\n",
       "      <td>0.374375</td>\n",
       "      <td>0.364375</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.038503</td>\n",
       "      <td>0.024060</td>\n",
       "      <td>0.093214</td>\n",
       "      <td>0.090714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "      <td>0.301525</td>\n",
       "      <td>0.313693</td>\n",
       "      <td>0.309089</td>\n",
       "      <td>0.331158</td>\n",
       "      <td>0.387865</td>\n",
       "      <td>0.452488</td>\n",
       "      <td>0.391385</td>\n",
       "      <td>0.441408</td>\n",
       "      <td>0.384375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215519</td>\n",
       "      <td>0.213593</td>\n",
       "      <td>0.347656</td>\n",
       "      <td>0.352656</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.255311</td>\n",
       "      <td>0.187394</td>\n",
       "      <td>0.016429</td>\n",
       "      <td>0.016429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama-2-13b</td>\n",
       "      <td>0.323594</td>\n",
       "      <td>0.334734</td>\n",
       "      <td>0.353455</td>\n",
       "      <td>0.365446</td>\n",
       "      <td>0.421750</td>\n",
       "      <td>0.449539</td>\n",
       "      <td>0.376201</td>\n",
       "      <td>0.408362</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350194</td>\n",
       "      <td>0.346815</td>\n",
       "      <td>0.355625</td>\n",
       "      <td>0.376250</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.034209</td>\n",
       "      <td>0.027695</td>\n",
       "      <td>0.198929</td>\n",
       "      <td>0.205893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>0.349043</td>\n",
       "      <td>0.376247</td>\n",
       "      <td>0.355007</td>\n",
       "      <td>0.390173</td>\n",
       "      <td>0.489223</td>\n",
       "      <td>0.552331</td>\n",
       "      <td>0.486278</td>\n",
       "      <td>0.541054</td>\n",
       "      <td>0.518750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227463</td>\n",
       "      <td>0.220500</td>\n",
       "      <td>0.396406</td>\n",
       "      <td>0.408281</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.568750</td>\n",
       "      <td>0.286907</td>\n",
       "      <td>0.252642</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.042500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>0.322603</td>\n",
       "      <td>0.351961</td>\n",
       "      <td>0.354197</td>\n",
       "      <td>0.391297</td>\n",
       "      <td>0.495903</td>\n",
       "      <td>0.585435</td>\n",
       "      <td>0.428984</td>\n",
       "      <td>0.509020</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229713</td>\n",
       "      <td>0.218074</td>\n",
       "      <td>0.380625</td>\n",
       "      <td>0.366250</td>\n",
       "      <td>0.500625</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.024703</td>\n",
       "      <td>0.024309</td>\n",
       "      <td>0.131071</td>\n",
       "      <td>0.133571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama-2-70b-chat</td>\n",
       "      <td>0.365819</td>\n",
       "      <td>0.402261</td>\n",
       "      <td>0.374817</td>\n",
       "      <td>0.416498</td>\n",
       "      <td>0.509007</td>\n",
       "      <td>0.618683</td>\n",
       "      <td>0.505382</td>\n",
       "      <td>0.583412</td>\n",
       "      <td>0.556250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228065</td>\n",
       "      <td>0.228546</td>\n",
       "      <td>0.384375</td>\n",
       "      <td>0.423125</td>\n",
       "      <td>0.541250</td>\n",
       "      <td>0.528750</td>\n",
       "      <td>0.317556</td>\n",
       "      <td>0.328511</td>\n",
       "      <td>0.027857</td>\n",
       "      <td>0.032857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama-3-70b-chat</td>\n",
       "      <td>0.451451</td>\n",
       "      <td>0.493406</td>\n",
       "      <td>0.452624</td>\n",
       "      <td>0.500807</td>\n",
       "      <td>0.606390</td>\n",
       "      <td>0.691563</td>\n",
       "      <td>0.565677</td>\n",
       "      <td>0.641054</td>\n",
       "      <td>0.653125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348130</td>\n",
       "      <td>0.358046</td>\n",
       "      <td>0.469062</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.656875</td>\n",
       "      <td>0.736875</td>\n",
       "      <td>0.444964</td>\n",
       "      <td>0.439295</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>davinci-002</td>\n",
       "      <td>0.293974</td>\n",
       "      <td>0.300627</td>\n",
       "      <td>0.323768</td>\n",
       "      <td>0.331345</td>\n",
       "      <td>0.413500</td>\n",
       "      <td>0.429911</td>\n",
       "      <td>0.361013</td>\n",
       "      <td>0.386524</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239769</td>\n",
       "      <td>0.234178</td>\n",
       "      <td>0.366875</td>\n",
       "      <td>0.356250</td>\n",
       "      <td>0.505625</td>\n",
       "      <td>0.506250</td>\n",
       "      <td>0.008729</td>\n",
       "      <td>0.011011</td>\n",
       "      <td>0.153929</td>\n",
       "      <td>0.153929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>0.358278</td>\n",
       "      <td>0.384165</td>\n",
       "      <td>0.368927</td>\n",
       "      <td>0.405154</td>\n",
       "      <td>0.468703</td>\n",
       "      <td>0.546873</td>\n",
       "      <td>0.510929</td>\n",
       "      <td>0.572572</td>\n",
       "      <td>0.476562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237456</td>\n",
       "      <td>0.248857</td>\n",
       "      <td>0.398750</td>\n",
       "      <td>0.413906</td>\n",
       "      <td>0.510625</td>\n",
       "      <td>0.508125</td>\n",
       "      <td>0.306299</td>\n",
       "      <td>0.311186</td>\n",
       "      <td>0.067321</td>\n",
       "      <td>0.067321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt-4-base</td>\n",
       "      <td>0.367979</td>\n",
       "      <td>0.392918</td>\n",
       "      <td>0.400690</td>\n",
       "      <td>0.426456</td>\n",
       "      <td>0.571579</td>\n",
       "      <td>0.621953</td>\n",
       "      <td>0.481007</td>\n",
       "      <td>0.621154</td>\n",
       "      <td>0.621875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344156</td>\n",
       "      <td>0.350357</td>\n",
       "      <td>0.473125</td>\n",
       "      <td>0.433125</td>\n",
       "      <td>0.459375</td>\n",
       "      <td>0.444375</td>\n",
       "      <td>0.028103</td>\n",
       "      <td>0.039450</td>\n",
       "      <td>0.168214</td>\n",
       "      <td>0.168214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0.421810</td>\n",
       "      <td>0.467279</td>\n",
       "      <td>0.444592</td>\n",
       "      <td>0.488289</td>\n",
       "      <td>0.606171</td>\n",
       "      <td>0.718308</td>\n",
       "      <td>0.569253</td>\n",
       "      <td>0.696159</td>\n",
       "      <td>0.635938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383158</td>\n",
       "      <td>0.377457</td>\n",
       "      <td>0.501719</td>\n",
       "      <td>0.483125</td>\n",
       "      <td>0.520938</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.278093</td>\n",
       "      <td>0.245550</td>\n",
       "      <td>0.063571</td>\n",
       "      <td>0.075536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>0.431952</td>\n",
       "      <td>0.515173</td>\n",
       "      <td>0.446519</td>\n",
       "      <td>0.529383</td>\n",
       "      <td>0.576621</td>\n",
       "      <td>0.727886</td>\n",
       "      <td>0.589057</td>\n",
       "      <td>0.726063</td>\n",
       "      <td>0.620313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340911</td>\n",
       "      <td>0.349257</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.591875</td>\n",
       "      <td>0.704375</td>\n",
       "      <td>0.331152</td>\n",
       "      <td>0.380532</td>\n",
       "      <td>0.100357</td>\n",
       "      <td>0.111607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0.463683</td>\n",
       "      <td>0.507234</td>\n",
       "      <td>0.477258</td>\n",
       "      <td>0.513523</td>\n",
       "      <td>0.594407</td>\n",
       "      <td>0.713464</td>\n",
       "      <td>0.657684</td>\n",
       "      <td>0.718357</td>\n",
       "      <td>0.678125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296388</td>\n",
       "      <td>0.294165</td>\n",
       "      <td>0.397500</td>\n",
       "      <td>0.440625</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.686250</td>\n",
       "      <td>0.384295</td>\n",
       "      <td>0.430613</td>\n",
       "      <td>0.111786</td>\n",
       "      <td>0.108750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>claude-instant-1.2</td>\n",
       "      <td>0.427225</td>\n",
       "      <td>0.439009</td>\n",
       "      <td>0.423851</td>\n",
       "      <td>0.440446</td>\n",
       "      <td>0.559998</td>\n",
       "      <td>0.625723</td>\n",
       "      <td>0.531454</td>\n",
       "      <td>0.588931</td>\n",
       "      <td>0.648438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302698</td>\n",
       "      <td>0.303679</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.399375</td>\n",
       "      <td>0.598125</td>\n",
       "      <td>0.557500</td>\n",
       "      <td>0.479858</td>\n",
       "      <td>0.438582</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>0.443042</td>\n",
       "      <td>0.461923</td>\n",
       "      <td>0.448176</td>\n",
       "      <td>0.471617</td>\n",
       "      <td>0.573427</td>\n",
       "      <td>0.626884</td>\n",
       "      <td>0.600779</td>\n",
       "      <td>0.619657</td>\n",
       "      <td>0.631250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260111</td>\n",
       "      <td>0.253851</td>\n",
       "      <td>0.408125</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>0.621875</td>\n",
       "      <td>0.596875</td>\n",
       "      <td>0.476653</td>\n",
       "      <td>0.541206</td>\n",
       "      <td>0.102500</td>\n",
       "      <td>0.097500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>claude-3-haiku</td>\n",
       "      <td>0.414209</td>\n",
       "      <td>0.457995</td>\n",
       "      <td>0.410822</td>\n",
       "      <td>0.454596</td>\n",
       "      <td>0.541717</td>\n",
       "      <td>0.619253</td>\n",
       "      <td>0.527729</td>\n",
       "      <td>0.626778</td>\n",
       "      <td>0.610938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278751</td>\n",
       "      <td>0.278699</td>\n",
       "      <td>0.396406</td>\n",
       "      <td>0.389531</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.516875</td>\n",
       "      <td>0.545638</td>\n",
       "      <td>0.625957</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>claude-3-sonnet</td>\n",
       "      <td>0.472193</td>\n",
       "      <td>0.500660</td>\n",
       "      <td>0.464489</td>\n",
       "      <td>0.485660</td>\n",
       "      <td>0.610016</td>\n",
       "      <td>0.655760</td>\n",
       "      <td>0.614713</td>\n",
       "      <td>0.671318</td>\n",
       "      <td>0.648438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303525</td>\n",
       "      <td>0.303457</td>\n",
       "      <td>0.463125</td>\n",
       "      <td>0.441875</td>\n",
       "      <td>0.505313</td>\n",
       "      <td>0.503750</td>\n",
       "      <td>0.726844</td>\n",
       "      <td>0.784574</td>\n",
       "      <td>0.043393</td>\n",
       "      <td>0.055893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>claude-3.5-sonnet</td>\n",
       "      <td>0.538626</td>\n",
       "      <td>0.571260</td>\n",
       "      <td>0.550110</td>\n",
       "      <td>0.579786</td>\n",
       "      <td>0.664905</td>\n",
       "      <td>0.714506</td>\n",
       "      <td>0.638930</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.764062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391028</td>\n",
       "      <td>0.393818</td>\n",
       "      <td>0.464687</td>\n",
       "      <td>0.493125</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.681250</td>\n",
       "      <td>0.578283</td>\n",
       "      <td>0.663654</td>\n",
       "      <td>0.270893</td>\n",
       "      <td>0.261964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>claude-3-opus</td>\n",
       "      <td>0.504067</td>\n",
       "      <td>0.534696</td>\n",
       "      <td>0.511842</td>\n",
       "      <td>0.540864</td>\n",
       "      <td>0.667358</td>\n",
       "      <td>0.708516</td>\n",
       "      <td>0.627561</td>\n",
       "      <td>0.665407</td>\n",
       "      <td>0.746875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346185</td>\n",
       "      <td>0.354343</td>\n",
       "      <td>0.506875</td>\n",
       "      <td>0.510938</td>\n",
       "      <td>0.643125</td>\n",
       "      <td>0.632812</td>\n",
       "      <td>0.536418</td>\n",
       "      <td>0.643706</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>0.127857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  SAD_Plain_Prompt  SAD_Situating_Prompt  \\\n",
       "0           llama-2-7b          0.328841              0.306368   \n",
       "1      llama-2-7b-chat          0.301525              0.313693   \n",
       "2          llama-2-13b          0.323594              0.334734   \n",
       "3     llama-2-13b-chat          0.349043              0.376247   \n",
       "4          llama-2-70b          0.322603              0.351961   \n",
       "5     llama-2-70b-chat          0.365819              0.402261   \n",
       "6     llama-3-70b-chat          0.451451              0.493406   \n",
       "7          davinci-002          0.293974              0.300627   \n",
       "8   gpt-3.5-turbo-0613          0.358278              0.384165   \n",
       "9           gpt-4-base          0.367979              0.392918   \n",
       "10          gpt-4-0613          0.421810              0.467279   \n",
       "11  gpt-4-0125-preview          0.431952              0.515173   \n",
       "12              gpt-4o          0.463683              0.507234   \n",
       "13  claude-instant-1.2          0.427225              0.439009   \n",
       "14          claude-2.1          0.443042              0.461923   \n",
       "15      claude-3-haiku          0.414209              0.457995   \n",
       "16     claude-3-sonnet          0.472193              0.500660   \n",
       "17   claude-3.5-sonnet          0.538626              0.571260   \n",
       "18       claude-3-opus          0.504067              0.534696   \n",
       "\n",
       "    SAD-lite_Plain_Prompt  SAD-lite_Situating_Prompt  SAD-mini_Plain_Prompt  \\\n",
       "0                0.364873                   0.340016               0.471816   \n",
       "1                0.309089                   0.331158               0.387865   \n",
       "2                0.353455                   0.365446               0.421750   \n",
       "3                0.355007                   0.390173               0.489223   \n",
       "4                0.354197                   0.391297               0.495903   \n",
       "5                0.374817                   0.416498               0.509007   \n",
       "6                0.452624                   0.500807               0.606390   \n",
       "7                0.323768                   0.331345               0.413500   \n",
       "8                0.368927                   0.405154               0.468703   \n",
       "9                0.400690                   0.426456               0.571579   \n",
       "10               0.444592                   0.488289               0.606171   \n",
       "11               0.446519                   0.529383               0.576621   \n",
       "12               0.477258                   0.513523               0.594407   \n",
       "13               0.423851                   0.440446               0.559998   \n",
       "14               0.448176                   0.471617               0.573427   \n",
       "15               0.410822                   0.454596               0.541717   \n",
       "16               0.464489                   0.485660               0.610016   \n",
       "17               0.550110                   0.579786               0.664905   \n",
       "18               0.511842                   0.540864               0.667358   \n",
       "\n",
       "    SAD-mini_Situating_Prompt  facts_Plain_Prompt  facts_Situating_Prompt  \\\n",
       "0                    0.418833            0.385027                0.360935   \n",
       "1                    0.452488            0.391385                0.441408   \n",
       "2                    0.449539            0.376201                0.408362   \n",
       "3                    0.552331            0.486278                0.541054   \n",
       "4                    0.585435            0.428984                0.509020   \n",
       "5                    0.618683            0.505382                0.583412   \n",
       "6                    0.691563            0.565677                0.641054   \n",
       "7                    0.429911            0.361013                0.386524   \n",
       "8                    0.546873            0.510929                0.572572   \n",
       "9                    0.621953            0.481007                0.621154   \n",
       "10                   0.718308            0.569253                0.696159   \n",
       "11                   0.727886            0.589057                0.726063   \n",
       "12                   0.713464            0.657684                0.718357   \n",
       "13                   0.625723            0.531454                0.588931   \n",
       "14                   0.626884            0.600779                0.619657   \n",
       "15                   0.619253            0.527729                0.626778   \n",
       "16                   0.655760            0.614713                0.671318   \n",
       "17                   0.714506            0.638930                0.675325   \n",
       "18                   0.708516            0.627561                0.665407   \n",
       "\n",
       "    influence_Plain_Prompt  ...  introspection_Plain_Prompt  \\\n",
       "0                 0.531250  ...                    0.379519   \n",
       "1                 0.384375  ...                    0.215519   \n",
       "2                 0.450000  ...                    0.350194   \n",
       "3                 0.518750  ...                    0.227463   \n",
       "4                 0.562500  ...                    0.229713   \n",
       "5                 0.556250  ...                    0.228065   \n",
       "6                 0.653125  ...                    0.348130   \n",
       "7                 0.421875  ...                    0.239769   \n",
       "8                 0.476562  ...                    0.237456   \n",
       "9                 0.621875  ...                    0.344156   \n",
       "10                0.635938  ...                    0.383158   \n",
       "11                0.620313  ...                    0.340911   \n",
       "12                0.678125  ...                    0.296388   \n",
       "13                0.648438  ...                    0.302698   \n",
       "14                0.631250  ...                    0.260111   \n",
       "15                0.610938  ...                    0.278751   \n",
       "16                0.648438  ...                    0.303525   \n",
       "17                0.764062  ...                    0.391028   \n",
       "18                0.746875  ...                    0.346185   \n",
       "\n",
       "    introspection_Situating_Prompt  stages_Plain_Prompt  \\\n",
       "0                         0.373241             0.374375   \n",
       "1                         0.213593             0.347656   \n",
       "2                         0.346815             0.355625   \n",
       "3                         0.220500             0.396406   \n",
       "4                         0.218074             0.380625   \n",
       "5                         0.228546             0.384375   \n",
       "6                         0.358046             0.469062   \n",
       "7                         0.234178             0.366875   \n",
       "8                         0.248857             0.398750   \n",
       "9                         0.350357             0.473125   \n",
       "10                        0.377457             0.501719   \n",
       "11                        0.349257             0.450000   \n",
       "12                        0.294165             0.397500   \n",
       "13                        0.303679             0.410000   \n",
       "14                        0.253851             0.408125   \n",
       "15                        0.278699             0.396406   \n",
       "16                        0.303457             0.463125   \n",
       "17                        0.393818             0.464687   \n",
       "18                        0.354343             0.506875   \n",
       "\n",
       "    stages_Situating_Prompt  self-recognition_Plain_Prompt  \\\n",
       "0                  0.364375                       0.500000   \n",
       "1                  0.352656                       0.500000   \n",
       "2                  0.376250                       0.500000   \n",
       "3                  0.408281                       0.512500   \n",
       "4                  0.366250                       0.500625   \n",
       "5                  0.423125                       0.541250   \n",
       "6                  0.484375                       0.656875   \n",
       "7                  0.356250                       0.505625   \n",
       "8                  0.413906                       0.510625   \n",
       "9                  0.433125                       0.459375   \n",
       "10                 0.483125                       0.520938   \n",
       "11                 0.468750                       0.591875   \n",
       "12                 0.440625                       0.720000   \n",
       "13                 0.399375                       0.598125   \n",
       "14                 0.415000                       0.621875   \n",
       "15                 0.389531                       0.510000   \n",
       "16                 0.441875                       0.505313   \n",
       "17                 0.493125                       0.662500   \n",
       "18                 0.510938                       0.643125   \n",
       "\n",
       "    self-recognition_Situating_Prompt  id-leverage_Plain_Prompt  \\\n",
       "0                            0.500000                  0.038503   \n",
       "1                            0.500000                  0.255311   \n",
       "2                            0.500000                  0.034209   \n",
       "3                            0.568750                  0.286907   \n",
       "4                            0.500000                  0.024703   \n",
       "5                            0.528750                  0.317556   \n",
       "6                            0.736875                  0.444964   \n",
       "7                            0.506250                  0.008729   \n",
       "8                            0.508125                  0.306299   \n",
       "9                            0.444375                  0.028103   \n",
       "10                           0.540000                  0.278093   \n",
       "11                           0.704375                  0.331152   \n",
       "12                           0.686250                  0.384295   \n",
       "13                           0.557500                  0.479858   \n",
       "14                           0.596875                  0.476653   \n",
       "15                           0.516875                  0.545638   \n",
       "16                           0.503750                  0.726844   \n",
       "17                           0.681250                  0.578283   \n",
       "18                           0.632812                  0.536418   \n",
       "\n",
       "    id-leverage_Situating_Prompt  anti-imitation_Plain_Prompt  \\\n",
       "0                       0.024060                     0.093214   \n",
       "1                       0.187394                     0.016429   \n",
       "2                       0.027695                     0.198929   \n",
       "3                       0.252642                     0.015000   \n",
       "4                       0.024309                     0.131071   \n",
       "5                       0.328511                     0.027857   \n",
       "6                       0.439295                     0.022321   \n",
       "7                       0.011011                     0.153929   \n",
       "8                       0.311186                     0.067321   \n",
       "9                       0.039450                     0.168214   \n",
       "10                      0.245550                     0.063571   \n",
       "11                      0.380532                     0.100357   \n",
       "12                      0.430613                     0.111786   \n",
       "13                      0.438582                     0.020000   \n",
       "14                      0.541206                     0.102500   \n",
       "15                      0.625957                     0.030000   \n",
       "16                      0.784574                     0.043393   \n",
       "17                      0.663654                     0.270893   \n",
       "18                      0.643706                     0.121429   \n",
       "\n",
       "    anti-imitation_Situating_Prompt  \n",
       "0                          0.090714  \n",
       "1                          0.016429  \n",
       "2                          0.205893  \n",
       "3                          0.042500  \n",
       "4                          0.133571  \n",
       "5                          0.032857  \n",
       "6                          0.022321  \n",
       "7                          0.153929  \n",
       "8                          0.067321  \n",
       "9                          0.168214  \n",
       "10                         0.075536  \n",
       "11                         0.111607  \n",
       "12                         0.108750  \n",
       "13                         0.022500  \n",
       "14                         0.097500  \n",
       "15                         0.040000  \n",
       "16                         0.055893  \n",
       "17                         0.261964  \n",
       "18                         0.127857  \n",
       "\n",
       "[19 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for c in sad_intermediary_df.columns:\n",
    "    if ' ' in c:\n",
    "        sad_intermediary_df.rename(columns={c: c.replace(' ', '_')}, inplace=True)\n",
    "\n",
    "sad_intermediary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct_llm_eval_with_agent = pd.merge(instruct_llm_benchmark_eval, sad_eval, on=\"Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt-4-0613',\n",
       " 'claude-2.0',\n",
       " 'claude-1.3',\n",
       " 'gpt-3.5-turbo-0613',\n",
       " 'claude-instant-1.1',\n",
       " 'codellama-34b-instruct',\n",
       " 'vicuna-13b-v1.5',\n",
       " 'llama-2-70b-chat',\n",
       " 'llama-2-13b-chat',\n",
       " 'vicuna-33b-v1.3',\n",
       " 'openchat-13b-v3.2',\n",
       " 'wizardlm-13b-v1.2',\n",
       " 'codellama-13b-instruct',\n",
       " 'vicuna-7b-v1.5',\n",
       " 'guanaco-65b',\n",
       " 'codellama-7b-instruct',\n",
       " 'wizardlm-30b-v1.0',\n",
       " 'guanaco-33b',\n",
       " 'koala-13b',\n",
       " 'llama-2-7b-chat',\n",
       " 'dolly-v2-12b',\n",
       " 'oasst-sft-4-pythia-12b-epoch-3.5',\n",
       " 'gpt-4-0314',\n",
       " 'deepseek-llm-67b-chat',\n",
       " 'lemur-70b-chat-v1',\n",
       " 'mistral-7b-instruct-v0.1',\n",
       " 'vicuna-13b-16k']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruct_llm_eval_with_agent['Model'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['llama-2-7b',\n",
       " 'llama-2-7b-chat',\n",
       " 'llama-2-13b',\n",
       " 'llama-2-13b-chat',\n",
       " 'llama-2-70b',\n",
       " 'llama-2-70b-chat',\n",
       " 'llama-3-70b-chat',\n",
       " 'davinci-002',\n",
       " 'gpt-3.5-turbo-0613',\n",
       " 'gpt-4-base',\n",
       " 'gpt-4-0613',\n",
       " 'gpt-4-0125-preview',\n",
       " 'gpt-4o',\n",
       " 'claude-instant-1.2',\n",
       " 'claude-2.1',\n",
       " 'claude-3-haiku',\n",
       " 'claude-3-sonnet',\n",
       " 'claude-3.5-sonnet',\n",
       " 'claude-3-opus']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sad_eval_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result_path = \"./eval_results/base_llm_benchmark_eval.csv\"\n",
    "base_eval = pd.read_csv(eval_result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meta-llama/Llama-2-7b-hf',\n",
       " 'meta-llama/Llama-2-13b-hf',\n",
       " 'meta-llama/Llama-2-70b-hf',\n",
       " 'huggyllama/llama-7b',\n",
       " 'huggyllama/llama-13b',\n",
       " 'huggyllama/llama-30b',\n",
       " 'huggyllama/llama-65b',\n",
       " 'meta-llama/Meta-Llama-3-70B',\n",
       " 'meta-llama/Meta-Llama-3-8B',\n",
       " 'Qwen/Qwen1.5-72B',\n",
       " 'Qwen/Qwen1.5-32B',\n",
       " 'Qwen/Qwen1.5-14B',\n",
       " 'Qwen/Qwen1.5-7B',\n",
       " 'Qwen/Qwen1.5-4B',\n",
       " 'Qwen/Qwen1.5-1.8B',\n",
       " 'Qwen/Qwen1.5-0.5B',\n",
       " 'Qwen/Qwen-72B',\n",
       " 'Qwen/Qwen-14B',\n",
       " 'Qwen/Qwen-7B',\n",
       " 'mistralai/Mistral-7B-v0.1',\n",
       " 'mistralai/Mixtral-8x7B-v0.1',\n",
       " '01-ai/Yi-6B',\n",
       " '01-ai/Yi-34B',\n",
       " 'google/gemma-7b',\n",
       " 'google/gemma-2b',\n",
       " 'tiiuae/falcon-180B',\n",
       " 'tiiuae/falcon-40b',\n",
       " 'tiiuae/falcon-7b',\n",
       " 'tiiuae/falcon-rw-1b',\n",
       " 'microsoft/phi-2',\n",
       " 'microsoft/phi-1_5',\n",
       " 'EleutherAI/pythia-1b-deduped',\n",
       " 'EleutherAI/pythia-410m-deduped',\n",
       " 'EleutherAI/pythia-6.9b-deduped',\n",
       " 'EleutherAI/pythia-2.8b-deduped',\n",
       " 'EleutherAI/pythia-12b-deduped',\n",
       " 'EleutherAI/pythia-70m-deduped',\n",
       " 'EleutherAI/pythia-1.4b-deduped',\n",
       " 'EleutherAI/pythia-160m-deduped',\n",
       " 'bigscience/bloom-560m',\n",
       " 'bigscience/bloom-1b1',\n",
       " 'bigscience/bloom-3b',\n",
       " 'bigscience/bloom-7b1',\n",
       " 'bigscience/bloom',\n",
       " 'EleutherAI/gpt-neox-20b',\n",
       " 'EleutherAI/gpt-neo-2.7B',\n",
       " 'EleutherAI/gpt-neo-1.3B',\n",
       " 'EleutherAI/gpt-neo-125m',\n",
       " 'EleutherAI/gpt-j-6b',\n",
       " 'facebook/opt-6.7b',\n",
       " 'facebook/opt-1.3b',\n",
       " 'facebook/opt-350m',\n",
       " 'facebook/opt-13b',\n",
       " 'facebook/opt-2.7b',\n",
       " 'facebook/opt-30b',\n",
       " 'facebook/opt-125m',\n",
       " 'facebook/opt-66b',\n",
       " 'mosaicml/mpt-30b',\n",
       " 'mosaicml/mpt-7b',\n",
       " 'facebook/xglm-564M',\n",
       " 'facebook/xglm-1.7B',\n",
       " 'facebook/xglm-4.5B',\n",
       " 'facebook/xglm-7.5B',\n",
       " 'codellama/CodeLlama-7b-hf',\n",
       " 'codellama/CodeLlama-13b-hf',\n",
       " 'codellama/CodeLlama-34b-hf',\n",
       " 'codellama/CodeLlama-70b-hf',\n",
       " 'bigcode/starcoderbase-1b',\n",
       " 'bigcode/starcoderbase-3b',\n",
       " 'bigcode/starcoderbase-7b',\n",
       " 'bigcode/starcoderbase',\n",
       " 'bigcode/starcoder2-15b',\n",
       " 'bigcode/starcoder2-7b',\n",
       " 'bigcode/starcoder2-3b',\n",
       " 'deepseek-ai/deepseek-coder-1.3b-base',\n",
       " 'deepseek-ai/deepseek-coder-6.7b-base',\n",
       " 'deepseek-ai/deepseek-coder-33b-base',\n",
       " '01-ai/Yi-6B-200K',\n",
       " '01-ai/Yi-34B-200K',\n",
       " 'openlm-research/open_llama_7b_v2',\n",
       " 'openlm-research/open_llama_3b_v2',\n",
       " 'openlm-research/open_llama_13b',\n",
       " 'openlm-research/open_llama_7b',\n",
       " 'openlm-research/open_llama_3b',\n",
       " 'openai-community/gpt2',\n",
       " 'openai-community/gpt2-large',\n",
       " 'internlm/internlm2-20b',\n",
       " 'internlm/internlm2-7b',\n",
       " 'deepseek-ai/deepseek-llm-67b-base',\n",
       " 'deepseek-ai/deepseek-moe-16b-base',\n",
       " 'Deci/DeciLM-7B',\n",
       " 'stabilityai/stablelm-base-alpha-7b-v2',\n",
       " 'stabilityai/stablelm-base-alpha-3b',\n",
       " 'stabilityai/stablelm-base-alpha-7b',\n",
       " 'stabilityai/stablelm-2-1_6b',\n",
       " 'RWKV/rwkv-4-169m-pile',\n",
       " 'RWKV/rwkv-4-430m-pile',\n",
       " 'RWKV/rwkv-4-1b5-pile',\n",
       " 'RWKV/rwkv-4-7b-pile',\n",
       " 'RWKV/rwkv-4-14b-pile',\n",
       " 'RWKV/rwkv-raven-14b',\n",
       " 'RWKV/rwkv-4-3b-pile',\n",
       " 'togethercomputer/RedPajama-INCITE-Base-3B-v1',\n",
       " 'togethercomputer/RedPajama-INCITE-Base-7B-v0.1',\n",
       " 'LLM360/Amber',\n",
       " 'Salesforce/codegen-6B-nl',\n",
       " 'Salesforce/codegen-16B-nl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_eval['Model'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
